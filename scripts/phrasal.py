#!/usr/local/bin/doit -f
#
# (The above location is the standard if pydoit is installed
#  via 'pip install doit'.
#
# A pydoit script for running the full Phrasal
# pipeline. This script replaces the old phrasal.sh.
#
# This script executes all underlying commands in a
# platform-independent manner.
#
# Author: Spence Green
#
import doit
from doit import get_var
from datetime import datetime
import sys
import yaml
import os
import os.path
from os.path import basename
import shutil
import shlex
import subprocess
import tempfile
import codecs
from cat import CatFile
import conf_keys as k
import re
import fileinput

#
# Doit configuration
#
DOIT_CONFIG = {
    # output from actions should be sent to the terminal/console
    'verbosity': 2,
    # use multi-processing / parallel execution
    'num_process': 1
}

# Get conf file from command-line arguments
#ARGS = sys.argv[1:]
ARGS = {"conf": get_var('conf', None)}
if 'conf' not in ARGS:
    raise RuntimeError

conf_file = ARGS['conf']
if not os.path.exists(conf_file):
    # Relative path
    conf_file = os.path.join(doit.get_initial_workdir(), conf_file)
    if not os.path.exists(conf_file):
        raise RuntimeError

# Conf file format is YAML. Parse it.
fd = open(conf_file)
CONFIG = yaml.load(fd)
fd.close()

# Constants for the files and folders generated by this script
# during execution
SYSTEM_DIR = CONFIG[k.SYSTEM_DIR]
p = lambda x : os.path.join(SYSTEM_DIR, x)
CHECKPOINT_DIR = p('checkpoints')
LOGS_DIR = p('logs')
COPY_DATA_LOC = 'copy-data'
COPY_DATA_DIR = p(COPY_DATA_LOC)
DECODER_INI = p('decoder.ini')
DECODER_TUNE_INI = p('decoder.tune.ini')

# Experiment naming
DATE = datetime.now().strftime('%a_%b_%d_%Y_%H_%M_%S')
EXPERIMENT_NAME = CONFIG[k.EXPERIMENT].get(k.EXPERIMENT_NAME, DATE) if k.EXPERIMENT in CONFIG else DATE

# Checkpoint files
p = lambda x : os.path.join(CHECKPOINT_DIR, '%s.%s' % (x, EXPERIMENT_NAME))
CHECKPOINT_SYSTEM_DIR = p(k.SYSTEM_DIR)
CHECKPOINT_COPY_DATA = p(k.TASK_COPY_DATA)
CHECKPOINT_TUNE = p(k.TASK_TUNE)
CHECKPOINT_BUILD = p(k.TASK_BUILD)

def qualify_path(path):
    if path.startswith(COPY_DATA_LOC):
        return os.path.join(SYSTEM_DIR, path)
    else:
        return path

def make_abs(path):
    return os.path.join(SYSTEM_DIR, basename(path))

# Global constants from the conf file. These are targets
# for the tasks below.
LM_FILE = qualify_path(CONFIG[k.TASK_LM][k.LM_OUTPUT])
TM_FILE = qualify_path(CONFIG[k.TASK_TM][k.TM_OUTPUT])
EVAL_FILE = '%s.%s.trans' % (CONFIG[k.TASK_EVAL][k.EVAL_SRC], EXPERIMENT_NAME) if k.TASK_EVAL in CONFIG else None
if EVAL_FILE:
    EVAL_FILE = make_abs(EVAL_FILE)
TUNE_WTS = make_abs('%s.online.final.binwts' % (EXPERIMENT_NAME))
LEARN_CURVE = make_abs('%s.learn-curve' % (EXPERIMENT_NAME))

# KenLM location in the Phrasal git repo
(PHRASAL_DIR, _) = os.path.split(sys.path[0])
KENLM_LIB = os.path.join(PHRASAL_DIR, 'src-cc')
KENLM_BIN = os.path.join(PHRASAL_DIR, 'src-cc', 'kenlm', 'bin')

def checkpoint(path, msg):
    """
    Make a checkpoint file on the local filesystem
    """
    with open(path, 'w') as outfile:
        outfile.write(msg + os.linesep)

def get_log_file_path(name):
    """
    Standardizes log file naming.
    """
    return os.path.join(LOGS_DIR, '%s.%s.log' % (EXPERIMENT_NAME, name))
        
def execute_shell_cmd(cmd, stdin=None, stdout=subprocess.PIPE, stderr=subprocess.STDOUT):
    """
    Executes a bash script as a sub-process. Execution is
    platform-dependent (i.e., a shell is required).

    Returns:
      The process handle.
    """
    return subprocess.Popen(cmd, shell=True,
                            cwd=SYSTEM_DIR, env=os.environ,
                            universal_newlines=True,
                            stdin=stdin,
                            stdout=stdout,
                            stderr=stderr)
    #    script_file = tempfile.NamedTemporaryFile('wt')
    #    script_file.write(script)
    #    script_file.flush()
    #    return subprocess.Popen(['bash', script_file.name], shell=True,


def get_java_cmd(class_str):
    """
    Get the user-specified JVM options
    """
    jvm_options = None
    if k.TASK_RUNTIME in CONFIG and k.RUNTIME_JVM in CONFIG[k.TASK_RUNTIME]:
        jvm_options = ' '.join(CONFIG[k.TASK_RUNTIME][k.RUNTIME_JVM])
    else:
        # Best GC settings for Phrasal as of JVM 1.8
        jvm_options = '-server -ea -Xmx5g -Xms5g -XX:+UseParallelGC -XX:+UseParallelOldGC -Djava.library.path=%s' % (KENLM_LIB)
    return 'java %s %s' % (jvm_options, class_str)

def task_mksystemdir():
    """
    Create the system directory and necessary sub-directories.
    """
    def make_dirs():
        if not os.path.exists(SYSTEM_DIR):
            os.makedirs(SYSTEM_DIR)
        if not os.path.exists(CHECKPOINT_DIR):
            os.makedirs(CHECKPOINT_DIR)
        if not os.path.exists(LOGS_DIR):
            os.makedirs(LOGS_DIR)
            
    return { 'actions' : [make_dirs],
             'targets' : [CHECKPOINT_SYSTEM_DIR]
         }
        
def task_build():
    """
    Build the Phrasal (git) repository.
    """
    def build_git_repo():
        if not k.TASK_BUILD in CONFIG:
            checkpoint(CHECKPOINT_BUILD, 'done')
            return
        d = CONFIG[k.TASK_BUILD]
        cwd = os.getcwd()
        for repo_path in d:
            os.chdir(repo_path)
            for action,value in d[repo_path].iteritems():
                if action == k.BUILD_BRANCH:
                    # Get the current branch
                    branch = value
                    p = execute_shell_cmd('git symbolic-ref --short -q HEAD')
                    current_branch = p.stdout.read()
                    retval = p.wait()
                    if current_branch != branch:
                        retval = execute_shell_cmd('git checkout ' + branch).wait()
                elif action == k.BUILD_CMD:
                    with open(get_log_file_path('build'), 'w') as log_file:
                        retval = execute_shell_cmd(value, stdout=log_file).wait()
            os.chdir(cwd)
        checkpoint(CHECKPOINT_BUILD, 'done')
            
    return { 'actions' : [build_git_repo],
             'targets' : [CHECKPOINT_BUILD]
         }
        
def task_copy_data():
    """
    Copy data from other places on the filesystem to the
    system directory.
    """
    def copy_remote_data():
        if not k.TASK_COPY_DATA in CONFIG:
            # Nothing to copy. Skip.
            checkpoint(CHECKPOINT_COPY_DATA, 'done')
            return
        if not os.path.exists(COPY_DATA_DIR):
            os.makedirs(COPY_DATA_DIR)
        d = CONFIG[k.TASK_COPY_DATA]
        if isinstance(d, list):
            for file_path in d:
                dest_path = os.path.join(COPY_DATA_DIR, basename(file_path))
                if not os.path.exists(dest_path):
                    shutil.copy2(file_path, COPY_DATA_DIR)
        else:
            dest_path = os.path.join(COPY_DATA_DIR, basename(d))
            if not os.path.exists(dest_path):
                shutil.copy2(d, COPY_DATA_DIR)
        checkpoint(CHECKPOINT_COPY_DATA, 'done')
    
    return { 'actions' : [copy_remote_data],
             'targets' : [CHECKPOINT_COPY_DATA]
         }

def task_compile_lm():
    """
    Calls KenLM to compile a language model.
    """
    def make_lm():
        if os.path.exists(LM_FILE):
            # Don't run KenLM if the LM already exists on disk
            # Otherwise, doit will always run this task at least
            # once.
            return
        mono_data = [CONFIG[k.CORPUS][k.CORPUS_TGT]]
        if k.CORPUS_MONO in CONFIG[k.CORPUS]:
            mono_files = CONFIG[k.CORPUS][k.CORPUS_MONO]
            if isinstance(mono_files, list):
                mono_data.extend(mono_files)
            else:
                mono_data.append(mono_files)
        bin_type = CONFIG[k.TASK_LM][k.LM_TYPE]
        options = ' '.join(CONFIG[k.TASK_LM][k.LM_OPTIONS])

        # Make the shell script for execution
        lmplz = os.path.join(KENLM_BIN, 'lmplz')
        build_bin = os.path.join(KENLM_BIN, 'build_binary')
        tmp_dir = os.path.join(SYSTEM_DIR, 'lm_tmp')
        if not os.path.exists(tmp_dir):
            os.makedirs(tmp_dir)

        # Compile ARPA file
        lmplz_cmd = "%s %s -T %s --arpa %s.arpa" % (lmplz, options, tmp_dir, LM_FILE)
        # Binarize ARPA file
        bin_cmd = "%s %s %s.arpa %s" % (build_bin, bin_type, LM_FILE, LM_FILE)
        with open(get_log_file_path('lm'), 'w') as log_file:
            with CatFile(mono_files) as infile:
                retval = execute_shell_cmd(lmplz_cmd, stdin=infile,
                                     stdout=log_file).wait()
            retval = execute_shell_cmd(bin_cmd, stdout=log_file).wait()
        shutil.rmtree(tmp_dir)
    
    return { 'actions' : [make_lm],
             'file_dep' : [CHECKPOINT_COPY_DATA],
             'targets' : [LM_FILE]
         }

def task_extract_tm():
    """
    Build a suffix-array based translation model.
    """
    def make_tm():
        if os.path.exists(TM_FILE):
            # Don't build the TM if it already exists on disk
            # Otherwise doit will run this task at least once
            return
        d = CONFIG[k.CORPUS]
        source = d[k.CORPUS_SRC]
        target = d[k.CORPUS_TGT]
        align = d[k.CORPUS_ALIGN]
        if isinstance(align, list):
            align = ' '.join(align)        
        tm_options = ' '.join(CONFIG[k.TASK_TM][k.TM_OPTIONS]) if k.TM_OPTIONS in CONFIG[k.TASK_TM] else ''
        jvm_options = get_jvm_options()
        java_cmd = get_jvm_cmd('edu.stanford.nlp.mt.train.DynamicTMBuilder')
        cmd = "%s %s %s %s %s %s" % (java_cmd, tm_options, TM_FILE, source, target, align)
        with open(get_log_file_path('tm'), 'w') as log_file:
            retval = execute_shell_cmd(cmd, stdout=log_file).wait()
        
    return { 'actions' : [make_tm],
             'file_dep' : [CHECKPOINT_COPY_DATA],
             'targets' : [TM_FILE]
         }

def generate_ini(filename, weights_file=None):
    """
    Generate a decoder ini file.
    """
    d = CONFIG[k.TASK_DECODER_CONFIG]
    # Convert to phrasal ini file parameter format
    to_param = lambda x : '[%s]' % (x)
    with open(filename, 'w') as outfile:
        ini = lambda x : outfile.write(str(x) + os.linesep)
        # Iterate over ini options
        for key in d[k.DECODER_OPTIONS]:
            ini(to_param(key))
            if isinstance(d[k.DECODER_OPTIONS][key], list):
                for value in d[k.DECODER_OPTIONS][key]:
                    ini(value)
            elif key == 'weights-file' and weights_file:
                pass
            else:
                ini(d[k.DECODER_OPTIONS][key])
            ini('')
        if weights_file:
            ini(to_param('weights-file'))
            ini(weights_file)
            ini('')

def task_tune():
    """
    Run tuning. Only supports online tuning right now.
    """
    def tune():
        # Check to see if decoder config contains a weights file
        # Or if the tuning task has been specified
        if not k.TASK_TUNE in CONFIG and 'weights-file' in CONFIG[k.TASK_DECODER_CONFIG][k.DECODER_OPTIONS]:
            # No need to run tuning
            shutil.copy2(CONFIG[k.TASK_DECODER_CONFIG][k.DECODER_OPTIONS]['weights-file'], TUNE_WTS)
            generate_ini(DECODER_INI)
            return

        # Run the tuner.
        generate_ini(DECODER_TUNE_INI)
        d = CONFIG[k.TASK_TUNE]
        source = d[k.TUNE_SRC]
        ref = d[k.TUNE_REFS]
        options = d[k.TUNE_OPTIONS]
        if isinstance(options, list):
            options = ' '.join(options)
        if isinstance(ref, list):
            options += ' -r ' + ','.join(ref)
            # Single ref as the argument to the tuning command
            ref = ref[0]
        options += ' -n ' + EXPERIMENT_NAME
        wts = d[k.TUNE_WTS]
        java_cmd = get_java_cmd('edu.stanford.nlp.mt.tune.OnlineTuner')
        cmd = '%s %s %s %s %s %s' % (java_cmd, source, ref, DECODER_TUNE_INI, wts, options)
        with open(get_log_file_path('tune'), 'w') as log_file:
            retval = execute_shell_cmd(cmd, stdout=log_file).wait()

        # Generate the decoder ini file
        generate_ini(DECODER_INI, TUNE_WTS)
        
    return { 'actions' : [tune],
             'file_dep' : [TM_FILE, LM_FILE],
             'targets' : [DECODER_INI, TUNE_WTS]
         }

def task_evaluate():
    """
    Decode and evaluate test set.
    """
    def decode():
        if not k.TASK_EVAL in CONFIG:
            return
        d = CONFIG[k.TASK_EVAL]
        src = qualify_path(d[k.EVAL_SRC])
        java_cmd = get_java_cmd('edu.stanford.nlp.mt.Phrasal')
        cmd = '%s %s -log-prefix %s' % (java_cmd, DECODER_INI, EXPERIMENT_NAME)
        with open(get_log_file_path('decode'), 'w') as log_file:
            with codecs.open(EVAL_FILE, 'w', encoding='utf-8') as outfile:
                with codecs.open(src, encoding='utf-8') as infile:
                    retval = execute_shell_cmd(cmd, stdin=infile, stdout=outfile, stderr=log_file).wait()
            
    def evaluate():
        """
        Evaluate a test set according to an evaluation metric.
        """
        if not os.path.exists(EVAL_FILE):
            # Nothing to evaluate
            return
        d = CONFIG[k.TASK_EVAL]
        metric = d[k.EVAL_METRIC]
        refs = d[k.EVAL_REFS]
        if isinstance(refs, list):
            refs = ' '.join(refs)
        java_cmd = get_java_cmd('edu.stanford.nlp.mt.tools.Evaluate')
        cmd = '%s %s %s' % (java_cmd, metric, refs)
        with open(get_log_file_path('evaluate'), 'w') as log_file:
            with codecs.open(EVAL_FILE, encoding='utf-8') as infile:
                with open(EVAL_FILE + '.eval', 'w') as outfile:
                    retval = execute_shell_cmd(cmd, stdin=infile,
                                               stdout=outfile,
                                               stderr=log_file).wait()
                
    return { 'actions' : [decode, evaluate],
             'file_dep' : [TM_FILE, LM_FILE, DECODER_INI],
             'targets' : [EVAL_FILE]
         }

def task_learning_curve():
    """
    Generate a learning curve. Requires execution of the tuning task.
    """
    def generate_curve():
        d = CONFIG[k.TASK_EVAL]
        metric = d[k.EVAL_METRIC]
        refs = d[k.EVAL_REFS]
        src = d[k.EVAL_SRC]
        if isinstance(refs, list):
            refs = ','.join(refs)
        all_wts = [x for x in os.listdir(SYSTEM_DIR) if re.search('\.binwts', x)]
        assert len(all_wts) > 0
        java_cmd = get_java_cmd('edu.stanford.nlp.mt.tools.OnlineLearningCurve')
        cmd = '%s %s %s %s %s %s' % (java_cmd, DECODER_INI,
                                     src, refs, metric,
                                     ' '.join(all_wts))
        with open(get_log_file_path('learn-curve'), 'w') as log_file:
            with open(LEARN_CURVE, 'w') as outfile:
                retval = execute_shell_cmd(cmd, stdout=outfile,
                                           stderr=log_file).wait()

    return { 'actions' : [generate_curve],
             'file_dep' : [TM_FILE, LM_FILE, DECODER_INI],
             'targets' : [LEARN_CURVE]
         }
